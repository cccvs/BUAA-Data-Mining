{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "182ba891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total node: 49730\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pytz\n",
    "from shapely.wkt import loads\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def str_to_time(time_str: str):\n",
    "    dt = datetime.strptime(time_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return int(dt.replace(tzinfo=pytz.UTC).timestamp())\n",
    "\n",
    "def time_to_str(timestamp):\n",
    "    dt_object = datetime.utcfromtimestamp(int(timestamp))\n",
    "    return dt_object.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "def cal_dist(c1, c2):\n",
    "    return geodesic(\n",
    "        (c1[1], c1[0]),\n",
    "        (c2[1], c2[0]),\n",
    "    ).meters\n",
    "\n",
    "# generate usr\n",
    "df_traj = pd.read_csv('data/traj.csv')\n",
    "df_usr = pd.DataFrame({'usr_id': df_traj['entity_id'].drop_duplicates().sort_values()})\n",
    "df_usr.to_csv('jump.usr', index=False)\n",
    "\n",
    "# generate geo\n",
    "def wkt_to_coordinates(wkt):\n",
    "    geom = loads(wkt)\n",
    "    return f\"[{geom.x}, {geom.y}]\"\n",
    "\n",
    "def wkt_to_list(wkt):\n",
    "    geom = loads(wkt)\n",
    "    return [geom.x, geom.y]\n",
    "\n",
    "df_node_split = pd.read_csv('data/node_split.csv')\n",
    "total_node = len(df_node_split['id'])\n",
    "print('total node:', total_node)\n",
    "\n",
    "# df_geo = pd.DataFrame({\n",
    "#     'geo_id': df_node_split['id'],  # Inheriting the 'geo_id' from 'id'\n",
    "#     'type': 'Point',  # Setting 'type' as 'Point' for all rows\n",
    "#     'coordinates': df_node_split['WKT'].apply(wkt_to_coordinates)  # Extracting coordinates from 'WKT'\n",
    "# })\n",
    "# df_geo.to_csv('jump.geo', index=False)\n",
    "# print(list(df_node_split['id']))\n",
    "# print(list(df_geo['coordinates']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5f5397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dyna\n",
    "\n",
    "df_road = pd.read_csv('data/road_split.csv')\n",
    "traj_to_entity = dict(zip(df_traj['traj_id'], df_traj['entity_id']))\n",
    "traj_to_time_list = {traj_id: list() for traj_id in traj_to_entity.keys()}  # {traj_id: [time1, time2, ...]}\n",
    "road_to_cost = dict(zip(df_road['id'], df_road['cost']))\n",
    "road_to_source = dict(zip(df_road['id'], df_road['source']))\n",
    "node_to_wktstr = dict(zip(df_node_split['id'], df_node_split['WKT']))\n",
    "node_to_coord = {node_id: wkt_to_list(wkt) for node_id, wkt in node_to_wktstr.items()}\n",
    "\n",
    "for traj_id, group in df_traj.groupby('traj_id'):\n",
    "    time_list = traj_to_time_list[traj_id]\n",
    "    for time in group['time']:\n",
    "        time_list.append(str_to_time(time))\n",
    "\n",
    "df_stmatch = pd.read_csv('data/mr_stmatch.csv', sep=';')\n",
    "df_stmatch = df_stmatch[df_stmatch['mgeom'] != 'LINESTRING()']\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4630f784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total node: 49730\n"
     ]
    }
   ],
   "source": [
    "list_coord = list(df_node_split['WKT'].apply(wkt_to_coordinates))\n",
    "total_node = len(df_node_split['id'])\n",
    "print('total node:', total_node)\n",
    "\n",
    "output_loc, output_time, output_entity = [], [], []\n",
    "def append_output(node_id, time_str, entity_id):\n",
    "    output_loc.append(node_id)\n",
    "    output_time.append(time_str)\n",
    "    output_entity.append(entity_id)\n",
    "\n",
    "for _, row in df_stmatch.iterrows():\n",
    "    traj_id = row.id\n",
    "    entity_id = traj_to_entity[traj_id]\n",
    "    # collect matching information\n",
    "    pgeom_wkt = loads(row.pgeom)\n",
    "    pgeom_list = [[point[0], point[1]] for point in pgeom_wkt.coords]\n",
    "    mgeom_wkt = loads(row.mgeom)\n",
    "    mgeom_list = [[point[0], point[1]] for point in mgeom_wkt.coords]\n",
    "    opath_list = [int(x) for x in row.opath.split(',')]\n",
    "    cpath_list = [int(x) for x in row.cpath.split(',')]\n",
    "    tpath_list = [[int(y) for y in x.split(',')] for x in row.tpath.split('|')]\n",
    "    # calculate duration\n",
    "    time_list = traj_to_time_list[traj_id]\n",
    "    duration_list = [time_list[i+1] - time_list[i] for i in range(len(time_list) - 1)]\n",
    "    # calculate cost\n",
    "    offset_list = [cal_dist(pgeom_list[i], node_to_coord[road_to_source[opath_list[i]]]) for i in range(len(pgeom_list))]\n",
    "    # offset_list = [0] * len(pgeom_list)\n",
    "    cost_list = list()\n",
    "    for i, tpath in enumerate(tpath_list):\n",
    "        cost = sum(road_to_cost[tpath[j]] for j in range(len(tpath) - 1))\n",
    "        cost_list.append(cost + offset_list[i+1] - offset_list[i])\n",
    "    # print(traj_id)\n",
    "    # print(\"pgeom_list: \" ,len(pgeom_list), pgeom_list)\n",
    "    # print(\"mgeom_list: \" ,len(mgeom_list), mgeom_list)\n",
    "    # print(\"cpath_list: \" ,len(cpath_list), cpath_list)\n",
    "    # print(\"tpath_list: \" ,len(tpath_list), tpath_list)\n",
    "    # print(\"time_list: \" ,len(time_list), time_list)\n",
    "    # print(\"duration_list: \" ,len(duration_list), duration_list)\n",
    "    # print(\"offset_list: \" ,len(offset_list), offset_list)\n",
    "    # print(\"cost_list: \" ,len(cost_list), cost_list)\n",
    "    \n",
    "    for i, tpath in enumerate(tpath_list):\n",
    "        append_output(len(list_coord), time_to_str(time_list[-1]), entity_id)\n",
    "        list_coord.append(str(pgeom_list[i]))\n",
    "        cost = road_to_cost[tpath[0]] - offset_list[i]\n",
    "        for j in range(len(tpath) - 1):\n",
    "            node_id = road_to_source[tpath[j+1]]\n",
    "            timestamp = time_list[i] + (duration_list[i] * (cost / cost_list[i])) if cost_list[i] else 0\n",
    "            append_output(node_id, time_to_str(timestamp), entity_id)\n",
    "            cost += road_to_cost[tpath[j+1]]\n",
    "    append_output(len(list_coord), time_to_str(time_list[-1]), entity_id)\n",
    "    list_coord.append(str(pgeom_list[-1]))\n",
    "    \n",
    "    # print(\"output_loc: \" ,len(output_loc), output_loc)\n",
    "    # print(\"output_time: \" ,len(output_time), output_time)\n",
    "    # print(\"output_entity: \" ,len(output_entity), output_entity)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3c1aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_geo = pd.DataFrame({\n",
    "    'geo_id': list(range(len(list_coord))),  # Inheriting the 'geo_id' from 'id'\n",
    "    'type': 'Point',  # Setting 'type' as 'Point' for all rows\n",
    "    'coordinates': list_coord # Extracting coordinates from 'WKT'\n",
    "})\n",
    "df_dyna = pd.DataFrame({\n",
    "    'location': output_loc,\n",
    "    'time': output_time,\n",
    "    'entity_id': output_entity,\n",
    "    'type': 'trajectory'\n",
    "})\n",
    "\n",
    "df_geo.to_csv('jump.geo', index=False)\n",
    "df_dyna.to_csv('jump.dyna', index=True, index_label='dyna_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148880c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
